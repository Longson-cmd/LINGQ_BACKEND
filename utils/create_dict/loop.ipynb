{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "add8792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61430\n",
      "['nativity', 'appliances', 'avenue', 'warlord', 'cicatrisation', 'handmade', 'affectionately', 'sankara', 'literahhy', 'muskrats', 'lihua', 'habilis', 'reexamine', 'sawyer', 'ogether', 'near', 'lonelier', 'popeyes', 'suns', 'apron']\n"
     ]
    }
   ],
   "source": [
    "from word2word import Word2word\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def clean_string(s: str) -> str:\n",
    "    # matches any digit OR any non-letter character\n",
    "    pattern = r\"[0-9]|[^a-zA-Z]\"\n",
    "\n",
    "    if re.search(pattern, s):\n",
    "        return \"\"\n",
    "    return s\n",
    "\n",
    "def clean_word(word: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize and clean a single English word.\n",
    "\n",
    "    Steps:\n",
    "        - Lowercase and strip whitespace.\n",
    "        - Normalize Unicode (NFKD) for consistent accents and symbols.\n",
    "        - Replace smart quotes and various dash symbols.\n",
    "        - Remove non-alphanumeric characters except apostrophes.\n",
    "\n",
    "    Returns:\n",
    "        str: cleaned word\n",
    "    \"\"\"\n",
    "    w = word.lower().strip()\n",
    "\n",
    "    w = unicodedata.normalize(\"NFKD\", w)\n",
    "\n",
    "    w = clean_string(w)\n",
    "    return w\n",
    "\n",
    "\n",
    "\n",
    "en2vi = Word2word(\"en\", \"vi\")\n",
    "\n",
    "english_words = list(en2vi.word2x.keys())\n",
    "\n",
    "\n",
    "\n",
    "list_english_cleaned = list(set([clean_word(w) for w in english_words if clean_word(w)]))\n",
    "\n",
    "list_english_sorted = sorted(list_english_cleaned)\n",
    "\n",
    "print(len(list_english_cleaned))      # total number of English words\n",
    "print(list_english_cleaned[:20])      # preview first 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1da018b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "list_verbs = []\n",
    "list_adverbs = []\n",
    "list_adjectives = []\n",
    "list_nouns = []\n",
    "list_rests = []\n",
    "\n",
    "for word in list_english_sorted:\n",
    "    synsets = wn.synsets(word)\n",
    "\n",
    "    # WordNet knows nothing about this word\n",
    "    if not synsets:\n",
    "        list_rests.append(word)\n",
    "        continue\n",
    "\n",
    "    pos_set = {syn.pos() for syn in synsets}\n",
    "\n",
    "    if 'v' in pos_set:\n",
    "        list_verbs.append(word)\n",
    "\n",
    "    if 'n' in pos_set:\n",
    "        list_nouns.append(word)\n",
    "\n",
    "    if 'a' in pos_set or 's' in pos_set:\n",
    "        list_adjectives.append(word)\n",
    "\n",
    "    if 'r' in pos_set:\n",
    "        list_adverbs.append(word)\n",
    "\n",
    "    # WordNet POS exists but not useful (very rare)\n",
    "    if not pos_set.intersection({'n', 'v', 'a', 's', 'r'}):\n",
    "        list_rests.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "831711c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14850\n",
      "1391\n",
      "7947\n",
      "27004\n",
      "21721\n"
     ]
    }
   ],
   "source": [
    "print(len(list_verbs))\n",
    "print(len(list_adverbs))\n",
    "print(len(list_adjectives))\n",
    "print(len(list_nouns))\n",
    "print(len(list_rests))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d621deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temporarily.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump({\n",
    "        'list_verbs': list_verbs,\n",
    "        'list_adverbs': list_adverbs,\n",
    "        'list_adjectives': list_adjectives,\n",
    "        'list_nouns': list_nouns,\n",
    "        'list_rests': list_rests,\n",
    "    }, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03543e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
